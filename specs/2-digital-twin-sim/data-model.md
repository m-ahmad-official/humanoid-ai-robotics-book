# Data Model: Digital Twin Simulation for Physical AI

## Key Entities

### Digital Twin
- **Name**: Digital Twin
- **Description**: A virtual representation of a physical robot or system that mirrors its real-world counterpart in real-time
- **Fields**:
  - twin_id: string (unique identifier for the digital twin)
  - physical_system_id: string (identifier for the corresponding physical system)
  - synchronization_rate: float (frequency of data synchronization between physical and virtual)
  - simulation_environment: string (Gazebo, Unity, or other simulation platform)
  - sensor_models: list of SensorModel objects (virtual sensors that mirror physical sensors)
  - actuator_models: list of ActuatorModel objects (virtual actuators that mirror physical actuators)
- **Relationships**: Connected to Physical System via synchronization protocols
- **Validation**: Must maintain real-time synchronization with physical counterpart

### Physics Simulation
- **Name**: Physics Simulation
- **Description**: Computational models that replicate real-world physics including gravity, collisions, and dynamics
- **Fields**:
  - simulation_id: string (unique identifier for the simulation)
  - gravity_constant: float (acceleration due to gravity in m/s²)
  - collision_detection: boolean (whether collision detection is enabled)
  - dynamics_solver: string (type of physics solver used)
  - time_step: float (simulation time step in seconds)
  - objects: list of PhysicalObject objects (objects in the simulation)
- **Relationships**: Contains Physical Objects and their interactions
- **Validation**: Must accurately replicate real-world physics within acceptable error margins

### Gazebo Environment
- **Name**: Gazebo Environment
- **Description**: A 3D simulation environment with physics engine, sensor simulation, and robot models
- **Fields**:
  - environment_name: string (name of the Gazebo world)
  - physics_engine: string (ODE, Bullet, or DART physics engine)
  - robot_models: list of RobotModel objects (robot models in the environment)
  - sensor_plugins: list of SensorPlugin objects (sensor plugins for simulation)
  - lighting_conditions: object (ambient light, directional light settings)
  - terrain: object (terrain properties and models)
- **Relationships**: Contains Robot Models and Sensor Plugins
- **Validation**: Must support ROS 2 communication and sensor simulation

### Unity Scene
- **Name**: Unity Scene
- **Description**: A 3D environment with high-fidelity rendering, lighting, and visual effects for realistic simulation
- **Fields**:
  - scene_name: string (name of the Unity scene)
  - rendering_quality: string (quality level: low, medium, high, ultra)
  - lighting_mode: string (realtime, mixed, or baked lighting)
  - objects: list of GameObject objects (3D objects in the scene)
  - camera_settings: object (camera properties for rendering)
  - post_processing: object (post-processing effects applied)
- **Relationships**: Contains GameObjects and rendering components
- **Validation**: Must support realistic visual rendering and sensor simulation

### Sensor Simulation
- **Name**: Sensor Simulation
- **Description**: Virtual sensors that generate data mimicking real-world sensors like LiDAR, cameras, and IMUs
- **Fields**:
  - sensor_type: string (LiDAR, depth camera, RGB camera, IMU, etc.)
  - sensor_id: string (unique identifier for the sensor)
  - simulated_data: object (the data generated by the sensor)
  - noise_model: object (noise characteristics to make simulation realistic)
  - update_rate: float (frequency of data updates in Hz)
  - field_of_view: float (field of view for visual sensors in degrees)
  - range_min: float (minimum detection range)
  - range_max: float (maximum detection range)
- **Relationships**: Attached to Robot Models in simulation environments
- **Validation**: Must generate realistic data that matches real sensor characteristics

### Human-Robot Interaction
- **Name**: Human-Robot Interaction
- **Description**: Interfaces and mechanisms that allow humans to interact with simulated robots in realistic ways
- **Fields**:
  - interaction_type: string (voice, gesture, GUI, physical manipulation, etc.)
  - interaction_device: string (keyboard, mouse, VR headset, haptic device, etc.)
  - interaction_context: string (environment or scenario for interaction)
  - user_input: object (input from human user)
  - robot_response: object (robot's response to human input)
  - safety_constraints: object (safety limits for interaction)
- **Relationships**: Connects Human Users to Robot Models
- **Validation**: Must ensure safe and realistic interaction scenarios

### Robot Model
- **Name**: Robot Model
- **Description**: 3D model of a robot with kinematic properties and sensor/actuator attachments
- **Fields**:
  - robot_name: string (name of the robot model)
  - urdf_path: string (path to URDF file describing the robot)
  - links: list of Link objects (rigid components of the robot)
  - joints: list of Joint objects (connections between links)
  - sensors: list of SensorSimulation objects (sensors attached to the robot)
  - actuators: list of Actuator objects (actuators for robot movement)
- **Relationships**: Contains Links, Joints, Sensors, and Actuators
- **Validation**: Must have valid kinematic structure and physical properties

## State Transitions

### Simulation Lifecycle
- **States**: Uninitialized → Initialized → Running → Paused → Stopped → Shutdown
- **Transitions**:
  - Created → Initialized: When simulation is created and configured
  - Initialized → Running: When simulation starts running
  - Running ↔ Paused: When simulation is paused/resumed
  - Running/Paused → Stopped: When simulation is stopped
  - Stopped → Shutdown: When simulation is completely shut down

### Sensor Data Flow
- **States**: Idle → Sensing → Processing → Publishing
- **Transitions**:
  - Idle → Sensing: When sensor starts collecting data
  - Sensing → Processing: When raw sensor data is processed
  - Processing → Publishing: When processed data is published to ROS 2 topics
  - Publishing → Idle: When sensor cycle completes

## Validation Rules

1. **Physics Accuracy**: All physics simulations must maintain accuracy within acceptable error margins
2. **Real-time Performance**: Simulations must maintain real-time performance for interactive use
3. **Sensor Realism**: Sensor simulations must generate realistic data that matches real hardware
4. **ROS 2 Compatibility**: All simulation components must be compatible with ROS 2
5. **Safety Constraints**: Human-robot interactions must enforce safety limits
6. **Synchronization**: Digital twins must maintain synchronization with physical systems